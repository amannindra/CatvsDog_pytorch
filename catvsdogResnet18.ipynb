{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e36ba74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\amann\\.cache\\kagglehub\\datasets\\karakaggle\\kaggle-cat-vs-dog-dataset\\versions\\1\\kagglecatsanddogs_3367a\n"
     ]
    }
   ],
   "source": [
    "# !conda install -y torchvision\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import time\n",
    "\n",
    "# PyTorch Library\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "\n",
    "# PyTorch Neural Network\n",
    "import torch.nn as nn\n",
    "\n",
    "# Allows us to transform data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Allows us to get the digit dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Creating graphs\n",
    "import torchvision.models as models\n",
    "import matplotlib.pylab as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Allows us to use arrays to manipulate and store data\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"karakaggle/kaggle-cat-vs-dog-dataset\")\n",
    "path = os.path.join(path, \"kagglecatsanddogs_3367a\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05f659f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "composed = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # Resize shortest side to 256\n",
    "        transforms.CenterCrop(224),  # Crop to 224x224\n",
    "        transforms.ToTensor(),  # Convert to tensor (scales to [0,1])\n",
    "        transforms.Normalize(  # Standardize using ImageNet stats\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ee1701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed7e309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000023BB7C70150>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000023B32174DD0>\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageFolder(os.path.join(path, \"train\"), transform=composed)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "val_data = ImageFolder(os.path.join(path, \"val\"), transform=composed)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=True)\n",
    "\n",
    "print(train_loader)\n",
    "print(val_loader)\n",
    "\n",
    "\n",
    "print(train_data[0][0].shape)\n",
    "# plt.imshow(train_data[0][0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91b8979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "<generator object Module.parameters at 0x0000023B25F209E0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]d:\\projects\\.venv\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [04:10<08:21, 250.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.002800000000000002\n",
      "The validaion  Cost for each epoch 1: 0.20157720670212234\n",
      "The validation accuracy for epoch 1: 0.9881810897435898\n",
      "epoch 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [05:47<02:39, 159.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0046\n",
      "The validaion  Cost for each epoch 2: 0.03941988147298849\n",
      "The validation accuracy for epoch 2: 0.9869791666666666\n",
      "epoch 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:16<00:00, 145.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.006400000000000001\n",
      "The validaion  Cost for each epoch 3: 0.03373696200112765\n",
      "The validation accuracy for epoch 3: 0.984375\n",
      "[0.9881810897435898, 0.9869791666666666, 0.984375]\n",
      "[0.20157720670212234, 0.03941988147298849, 0.03373696200112765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = linear_model(input_size, output_size)\n",
    "model = models.resnet18(pretrained=True)\n",
    "print(model)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "lr_scheduler = True\n",
    "\n",
    "base_lr = 0.001\n",
    "\n",
    "max_lr = 0.01\n",
    "\n",
    "momentum = 0.9\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "learning_rate = 5e-05\n",
    "\n",
    "print(model.parameters())\n",
    "\n",
    "optimizer_SGD = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "optimizer_Adam = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if lr_scheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "        optimizer_SGD,\n",
    "        base_lr=base_lr,\n",
    "        max_lr=max_lr,\n",
    "        step_size_up=5,\n",
    "        mode=\"triangular2\",\n",
    "    )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, epochs, print_=True\n",
    "):\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    correct = 0\n",
    "    # global:val_loader\n",
    "    n_test = len(val_data)\n",
    "    accuracy_best = 0\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        loss_sublist = []\n",
    "        # Loop through the data in loader\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            z = model(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss_sublist.append(loss.data.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "        print(\"epoch {} done\".format(epoch))\n",
    "\n",
    "        scheduler.step()\n",
    "        loss_list.append(np.mean(loss_sublist))\n",
    "        correct = 0\n",
    "\n",
    "        for x_test, y_test in val_loader:\n",
    "            x_test, y_test = x_test.to(\"cuda\"), y_test.to(\"cuda\")\n",
    "            model.eval()\n",
    "            z = model(x_test)\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / n_test\n",
    "        accuracy_list.append(accuracy)\n",
    "        if accuracy > accuracy_best:\n",
    "            accuracy_best = accuracy\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if print_:\n",
    "            print(\"learning rate\", optimizer.param_groups[0][\"lr\"])\n",
    "            print(\n",
    "                \"The validaion  Cost for each epoch \"\n",
    "                + str(epoch + 1)\n",
    "                + \": \"\n",
    "                + str(np.mean(loss_sublist))\n",
    "            )\n",
    "            print(\n",
    "                \"The validation accuracy for epoch \"\n",
    "                + str(epoch + 1)\n",
    "                + \": \"\n",
    "                + str(accuracy)\n",
    "            )\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    return accuracy_list, loss_list, model\n",
    "\n",
    "\n",
    "accuracy_list, loss_list, model = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer_SGD, epochs\n",
    ")\n",
    "print(accuracy_list)\n",
    "print(loss_list)\n",
    "\n",
    "# PlotParameters(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31b5f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c3d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
